{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics Vidhya JanataHack Solution:\n",
    "---\n",
    "\n",
    "Solution to the Analytics Vidhya's [JanataHack ML Hackathon](https://datahack.analyticsvidhya.com/contest/janatahack-e-commerce-analytics-ml-hackathon/).<br>\n",
    "**Problem Statement**: Predict the gender of e-commerceâ€™s participants from their product viewing records.<br>\n",
    "**Leaderboard Info**: 86.8% on public leaderboard, 87.6% on private leaderboard (Rank 42, top 10%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents:\n",
    "---\n",
    "1. Imports and Loading Data\n",
    "2. Miscellaneous Variables\n",
    "3. Feature Engineering\n",
    "4. Preparing the data\n",
    "5. Model and Submission\n",
    "\n",
    "\n",
    "## 1. Imports and Loading Data:\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "from category_encoders.cat_boost import CatBoostEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Miscellaneous Variables:\n",
    "---\n",
    "\n",
    "Just defined a list of the features to be used and initialising lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns are: session_id startTime endTime ProductList gender\n"
     ]
    }
   ],
   "source": [
    "print(\"The columns are:\", *list(train.columns))\n",
    "\n",
    "features = ['feat_A', 'feat_B', 'feat_C', 'feat_D', 'seconds']\n",
    "cat_cols = ['feat_A', 'feat_B', 'feat_C', 'feat_D']\n",
    "\n",
    "encs_cb = []\n",
    "encs_ohe = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering:\n",
    "---\n",
    "\n",
    "* Used only 2 features:\n",
    "  1. Calculated time in seconds from difference of endTime and startTime\n",
    "  2. Split the first product of the list into an A, B, C and D columns.<br><br>\n",
    "   So if x = A00002/B00003/C00006/D28435/<br>\n",
    "   x[:6]    = A00002<br>\n",
    "   x[7:13]  = B00003<br>\n",
    "   x[14:20] = C00006<br>\n",
    "   x[21:27] = D28435<br><br>\n",
    "   I used CatBoostEncoder as well as OneHotEncoder, doing both improved leaderboard accuracy than just single encoding\n",
    "\n",
    "* I tested more features but these were the minimal set of features that worked well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data, train=True):\n",
    "    enc_val = []\n",
    "    \n",
    "    # Calculating the time (in seconds) for each session_id\n",
    "    time = (pd.to_datetime(data['endTime']) - pd.to_datetime(data['startTime']))\n",
    "    data['seconds'] = time.apply(lambda x: x.total_seconds() * 60)      \n",
    "    \n",
    "    # Slicing the A B C D for the first product for each session_id\n",
    "    data['feat_A'] = data['ProductList'].apply(lambda x: x[:6])\n",
    "    data['feat_B'] = data['ProductList'].apply(lambda x: x[7:13])\n",
    "    data['feat_C'] = data['ProductList'].apply(lambda x: x[14:20])\n",
    "    data['feat_D'] = data['ProductList'].apply(lambda x: x[21:27])   \n",
    "    \n",
    "    if train:\n",
    "        # only for training dataset\n",
    "        data['gender'] = data['gender'].map({'male': 0, 'female': 1})    \n",
    "        for col in cat_cols:\n",
    "            # Cat Boost Encoder\n",
    "            cb = CatBoostEncoder()\n",
    "            cb.fit(data[col].values.reshape(-1, 1), data['gender'])\n",
    "            # One Hot Encoder\n",
    "            ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "            ohe.fit(data[col].values.reshape(-1, 1))   \n",
    "            # Storing these encoder objects for test set\n",
    "            encs_cb.append(cb)\n",
    "            encs_ohe.append(ohe)\n",
    "    \n",
    "    # Transforming the data\n",
    "    for i, enc in enumerate(encs_ohe):\n",
    "        enc_val.append(enc.transform(data[cat_cols[i]].values.reshape(-1, 1)))\n",
    "    for i, enc in enumerate(encs_cb):\n",
    "        data[cat_cols[i]] = enc.transform(data[cat_cols[i]].values.reshape(-1, 1))     \n",
    "\n",
    "    return data[features].values, enc_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preparing the data:\n",
    "---\n",
    "* The train features (seconds and CatBoost encoding) and the one-hot encoded features are concatenated using hstack from scipy as normal concatenation does not work with sparse matrices.\n",
    "\n",
    "* Did a simple train-test split (80-20). Since the classes are imbalanced, the split is stratified (equal class ratios in train and validation set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, vals1 = clean_data(train)\n",
    "X_test, vals2 = clean_data(test, False)\n",
    "\n",
    "X = hstack(vals1)\n",
    "X_test = hstack(vals2)\n",
    "\n",
    "X = hstack((X, train[features].values))\n",
    "X_test = hstack((X_test, test[features].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['gender'].values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model and Submission:\n",
    "---\n",
    "* Used a GradientBoostingClassifier with max_depth of 2 and 50 estimators.\n",
    "* These parameters were achieved from trial and error, better methods like GridSearchCV can be done.\n",
    "* Once these parameters were found, fit on the full data, not just train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy, Loss:  0.8894047619047619 3.8198853110026443\n",
      "Val Accuracy, Loss:  0.8961904761904762 3.5855121869035003\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=50, max_depth=2)\n",
    "model.fit(X, y)\n",
    "print(\"Train Accuracy, Loss: \", accuracy_score(y_train, model.predict(X_train)), log_loss(y_train, model.predict(X_train)))\n",
    "print(\"Val Accuracy, Loss: \", accuracy_score(y_val, model.predict(X_val)), log_loss(y_val, model.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)\n",
    "sub = pd.DataFrame({'session_id': test['session_id'], 'gender': pd.Series(preds).map({0: 'male', 1: 'female'})})\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
